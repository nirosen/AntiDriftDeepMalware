from typing import Tuple, Union

from torch import nn, Tensor, ones, exp
from torch.nn import functional as F


class ConceptDriftModel(nn.Module):
    def __init__(
        self,
        init_correctness_scores: Union[Tuple[float, float], Tensor] = 0.9,
        init_decay_rate: float = 0.01,
        init_noise_power: float = 0.1,
        init_nondrifting_quantile: float = 0.2,
    ):
        super().__init__()
        self.N = nn.Parameter(init_noise_power * ones(1, 2))  # Noise power
        self.a = nn.Parameter(-init_decay_rate * ones(1, 2))  # dynaic coefficient
        self.drifting = nn.Parameter(
            (1 - init_nondrifting_quantile) * Tensor(init_correctness_scores)
        )  # inital "corrctness" probability that's lost over time.
        self.non_drifting = nn.Parameter(
            Tensor(init_correctness_scores) * init_nondrifting_quantile
        )  # inital "corrctness" probability that stays long term.

    def forward(self, time_elapsed):
        decay = exp(time_elapsed * self.a)
        base_score = self.drifting * decay + self.non_drifting
        return F.log_softmax(base_score, dim=1)


def get_beta_stats(num_correct, num_mistakes):
    a = 1 + num_correct
    b = 1 + num_mistakes
    prob_mean = a / (a + b)
    prob_std = a * b / ((a + b + 1) * ((a + b) ** 2))
    return prob_mean, prob_std


if __name__ == "__main__":
    cdm = ConceptDriftModel((5, 1.3))
    # Try both BCELoss and MSELoss. Try also BCEWithLogitsLoss
    print(cdm(0), cdm(4), cdm(1e6))